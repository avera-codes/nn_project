{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as T\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplcyberpunk\n",
    "\n",
    "plt.style.use(\"cyberpunk\")\n",
    "import numpy as np\n",
    "import torchutils as tu\n",
    "import os\n",
    "import json\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(data_dir):\n",
    "    classes = sorted(os.listdir(data_dir))\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classes = get_classes(\"/home/artemiy/nn_project/data/seg_test/seg_test\")\n",
    "train_classes = get_classes(\"/home/artemiy/nn_project/data/seg_train/seg_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n"
     ]
    }
   ],
   "source": [
    "print(test_classes)\n",
    "print(train_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_class_index(data_dir):\n",
    "    classes = get_classes(data_dir)\n",
    "    class_index = {i: class_name for i, class_name in enumerate(classes)}\n",
    "    return class_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/home/artemiy/nn_project/data/seg_train/seg_train\"\n",
    "test_dir = \"/home/artemiy/nn_project/data/seg_test/seg_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = get_classes(train_dir)\n",
    "test_classes = get_classes(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class index: {0: 'buildings', 1: 'forest', 2: 'glacier', 3: 'mountain', 4: 'sea', 5: 'street'}\n"
     ]
    }
   ],
   "source": [
    "# Создание и сохранение словаря классов\n",
    "class_index = create_class_index(train_dir)\n",
    "with open(\"class_index.json\", \"w\") as f:\n",
    "    json.dump(class_index, f)\n",
    "\n",
    "print(\"Class index:\", class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = json.load(open(\"class_index.json\"))\n",
    "decode = lambda x: labels[str(x)] if str(x) in labels else 'Мы не знаем что это такое если бы мы знали мы не знаем что это такое'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0 corresponds to class buildings\n",
      "Index 1 corresponds to class forest\n",
      "Index 2 corresponds to class glacier\n",
      "Index 3 corresponds to class mountain\n",
      "Index 4 corresponds to class sea\n",
      "Index 5 corresponds to class street\n"
     ]
    }
   ],
   "source": [
    "# Проверка функции декодирования\n",
    "for i in range(len(labels)):\n",
    "    print(f\"Index {i} corresponds to class {decode(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Мы не знаем что это такое если бы мы знали мы не знаем что это такое ымпп укцрукер цкерц'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /home/artemiy/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import Inception_V3_Weights, inception_v3\n",
    "model = inception_v3(weights=Inception_V3_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================================\n",
      "Layer                                              Kernel              Output          Params             FLOPs\n",
      "===============================================================================================================\n",
      "0_Conv2d_1a_3x3.Conv2d_conv                       [3, 32, 3, 3]   [3, 32, 149, 149]         864      57,544,992\n",
      "1_Conv2d_1a_3x3.BatchNorm2d_bn                             [32]   [3, 32, 149, 149]          64       8,525,184\n",
      "2_Conv2d_2a_3x3.Conv2d_conv                      [32, 32, 3, 3]   [3, 32, 147, 147]       9,216     597,445,632\n",
      "3_Conv2d_2a_3x3.BatchNorm2d_bn                             [32]   [3, 32, 147, 147]          64       8,297,856\n",
      "4_Conv2d_2b_3x3.Conv2d_conv                      [32, 64, 3, 3]   [3, 64, 147, 147]      18,432   1,194,891,264\n",
      "5_Conv2d_2b_3x3.BatchNorm2d_bn                             [64]   [3, 64, 147, 147]         128      16,595,712\n",
      "6_maxpool1                                                    -     [3, 64, 73, 73]           0               0\n",
      "7_Conv2d_3b_1x1.Conv2d_conv                      [64, 80, 1, 1]     [3, 80, 73, 73]       5,120      81,853,440\n",
      "8_Conv2d_3b_1x1.BatchNorm2d_bn                             [80]     [3, 80, 73, 73]         160       5,115,840\n",
      "9_Conv2d_4a_3x3.Conv2d_conv                     [80, 192, 3, 3]    [3, 192, 71, 71]     138,240   2,090,603,520\n",
      "10_Conv2d_4a_3x3.BatchNorm2d_bn                           [192]    [3, 192, 71, 71]         384      11,614,464\n",
      "11_maxpool2                                                   -    [3, 192, 35, 35]           0               0\n",
      "12_Mixed_5b.branch1x1.Conv2d_conv               [192, 64, 1, 1]     [3, 64, 35, 35]      12,288      45,158,400\n",
      "13_Mixed_5b.branch1x1.BatchNorm2d_bn                       [64]     [3, 64, 35, 35]         128         940,800\n",
      "14_Mixed_5b.branch5x5_1.Conv2d_conv             [192, 48, 1, 1]     [3, 48, 35, 35]       9,216      33,868,800\n",
      "15_Mixed_5b.branch5x5_1.BatchNorm2d_bn                     [48]     [3, 48, 35, 35]          96         705,600\n",
      "16_Mixed_5b.branch5x5_2.Conv2d_conv              [48, 64, 5, 5]     [3, 64, 35, 35]      76,800     282,240,000\n",
      "17_Mixed_5b.branch5x5_2.BatchNorm2d_bn                     [64]     [3, 64, 35, 35]         128         940,800\n",
      "18_Mixed_5b.branch3x3dbl_1.Conv2d_conv          [192, 64, 1, 1]     [3, 64, 35, 35]      12,288      45,158,400\n",
      "19_Mixed_5b.branch3x3dbl_1.BatchNorm2d_bn                  [64]     [3, 64, 35, 35]         128         940,800\n",
      "20_Mixed_5b.branch3x3dbl_2.Conv2d_conv           [64, 96, 3, 3]     [3, 96, 35, 35]      55,296     203,212,800\n",
      "21_Mixed_5b.branch3x3dbl_2.BatchNorm2d_bn                  [96]     [3, 96, 35, 35]         192       1,411,200\n",
      "22_Mixed_5b.branch3x3dbl_3.Conv2d_conv           [96, 96, 3, 3]     [3, 96, 35, 35]      82,944     304,819,200\n",
      "23_Mixed_5b.branch3x3dbl_3.BatchNorm2d_bn                  [96]     [3, 96, 35, 35]         192       1,411,200\n",
      "24_Mixed_5b.branch_pool.Conv2d_conv             [192, 32, 1, 1]     [3, 32, 35, 35]       6,144      22,579,200\n",
      "25_Mixed_5b.branch_pool.BatchNorm2d_bn                     [32]     [3, 32, 35, 35]          64         470,400\n",
      "26_Mixed_5c.branch1x1.Conv2d_conv               [256, 64, 1, 1]     [3, 64, 35, 35]      16,384      60,211,200\n",
      "27_Mixed_5c.branch1x1.BatchNorm2d_bn                       [64]     [3, 64, 35, 35]         128         940,800\n",
      "28_Mixed_5c.branch5x5_1.Conv2d_conv             [256, 48, 1, 1]     [3, 48, 35, 35]      12,288      45,158,400\n",
      "29_Mixed_5c.branch5x5_1.BatchNorm2d_bn                     [48]     [3, 48, 35, 35]          96         705,600\n",
      "30_Mixed_5c.branch5x5_2.Conv2d_conv              [48, 64, 5, 5]     [3, 64, 35, 35]      76,800     282,240,000\n",
      "31_Mixed_5c.branch5x5_2.BatchNorm2d_bn                     [64]     [3, 64, 35, 35]         128         940,800\n",
      "32_Mixed_5c.branch3x3dbl_1.Conv2d_conv          [256, 64, 1, 1]     [3, 64, 35, 35]      16,384      60,211,200\n",
      "33_Mixed_5c.branch3x3dbl_1.BatchNorm2d_bn                  [64]     [3, 64, 35, 35]         128         940,800\n",
      "34_Mixed_5c.branch3x3dbl_2.Conv2d_conv           [64, 96, 3, 3]     [3, 96, 35, 35]      55,296     203,212,800\n",
      "35_Mixed_5c.branch3x3dbl_2.BatchNorm2d_bn                  [96]     [3, 96, 35, 35]         192       1,411,200\n",
      "36_Mixed_5c.branch3x3dbl_3.Conv2d_conv           [96, 96, 3, 3]     [3, 96, 35, 35]      82,944     304,819,200\n",
      "37_Mixed_5c.branch3x3dbl_3.BatchNorm2d_bn                  [96]     [3, 96, 35, 35]         192       1,411,200\n",
      "38_Mixed_5c.branch_pool.Conv2d_conv             [256, 64, 1, 1]     [3, 64, 35, 35]      16,384      60,211,200\n",
      "39_Mixed_5c.branch_pool.BatchNorm2d_bn                     [64]     [3, 64, 35, 35]         128         940,800\n",
      "40_Mixed_5d.branch1x1.Conv2d_conv               [288, 64, 1, 1]     [3, 64, 35, 35]      18,432      67,737,600\n",
      "41_Mixed_5d.branch1x1.BatchNorm2d_bn                       [64]     [3, 64, 35, 35]         128         940,800\n",
      "42_Mixed_5d.branch5x5_1.Conv2d_conv             [288, 48, 1, 1]     [3, 48, 35, 35]      13,824      50,803,200\n",
      "43_Mixed_5d.branch5x5_1.BatchNorm2d_bn                     [48]     [3, 48, 35, 35]          96         705,600\n",
      "44_Mixed_5d.branch5x5_2.Conv2d_conv              [48, 64, 5, 5]     [3, 64, 35, 35]      76,800     282,240,000\n",
      "45_Mixed_5d.branch5x5_2.BatchNorm2d_bn                     [64]     [3, 64, 35, 35]         128         940,800\n",
      "46_Mixed_5d.branch3x3dbl_1.Conv2d_conv          [288, 64, 1, 1]     [3, 64, 35, 35]      18,432      67,737,600\n",
      "47_Mixed_5d.branch3x3dbl_1.BatchNorm2d_bn                  [64]     [3, 64, 35, 35]         128         940,800\n",
      "48_Mixed_5d.branch3x3dbl_2.Conv2d_conv           [64, 96, 3, 3]     [3, 96, 35, 35]      55,296     203,212,800\n",
      "49_Mixed_5d.branch3x3dbl_2.BatchNorm2d_bn                  [96]     [3, 96, 35, 35]         192       1,411,200\n",
      "50_Mixed_5d.branch3x3dbl_3.Conv2d_conv           [96, 96, 3, 3]     [3, 96, 35, 35]      82,944     304,819,200\n",
      "51_Mixed_5d.branch3x3dbl_3.BatchNorm2d_bn                  [96]     [3, 96, 35, 35]         192       1,411,200\n",
      "52_Mixed_5d.branch_pool.Conv2d_conv             [288, 64, 1, 1]     [3, 64, 35, 35]      18,432      67,737,600\n",
      "53_Mixed_5d.branch_pool.BatchNorm2d_bn                     [64]     [3, 64, 35, 35]         128         940,800\n",
      "54_Mixed_6a.branch3x3.Conv2d_conv              [288, 384, 3, 3]    [3, 384, 17, 17]     995,328     862,949,376\n",
      "55_Mixed_6a.branch3x3.BatchNorm2d_bn                      [384]    [3, 384, 17, 17]         768       1,331,712\n",
      "56_Mixed_6a.branch3x3dbl_1.Conv2d_conv          [288, 64, 1, 1]     [3, 64, 35, 35]      18,432      67,737,600\n",
      "57_Mixed_6a.branch3x3dbl_1.BatchNorm2d_bn                  [64]     [3, 64, 35, 35]         128         940,800\n",
      "58_Mixed_6a.branch3x3dbl_2.Conv2d_conv           [64, 96, 3, 3]     [3, 96, 35, 35]      55,296     203,212,800\n",
      "59_Mixed_6a.branch3x3dbl_2.BatchNorm2d_bn                  [96]     [3, 96, 35, 35]         192       1,411,200\n",
      "60_Mixed_6a.branch3x3dbl_3.Conv2d_conv           [96, 96, 3, 3]     [3, 96, 17, 17]      82,944      71,912,448\n",
      "61_Mixed_6a.branch3x3dbl_3.BatchNorm2d_bn                  [96]     [3, 96, 17, 17]         192         332,928\n",
      "62_Mixed_6b.branch1x1.Conv2d_conv              [768, 192, 1, 1]    [3, 192, 17, 17]     147,456     127,844,352\n",
      "63_Mixed_6b.branch1x1.BatchNorm2d_bn                      [192]    [3, 192, 17, 17]         384         665,856\n",
      "64_Mixed_6b.branch7x7_1.Conv2d_conv            [768, 128, 1, 1]    [3, 128, 17, 17]      98,304      85,229,568\n",
      "65_Mixed_6b.branch7x7_1.BatchNorm2d_bn                    [128]    [3, 128, 17, 17]         256         443,904\n",
      "66_Mixed_6b.branch7x7_2.Conv2d_conv            [128, 128, 1, 7]    [3, 128, 17, 17]     114,688      99,434,496\n",
      "67_Mixed_6b.branch7x7_2.BatchNorm2d_bn                    [128]    [3, 128, 17, 17]         256         443,904\n",
      "68_Mixed_6b.branch7x7_3.Conv2d_conv            [128, 192, 7, 1]    [3, 192, 17, 17]     172,032     149,151,744\n",
      "69_Mixed_6b.branch7x7_3.BatchNorm2d_bn                    [192]    [3, 192, 17, 17]         384         665,856\n",
      "70_Mixed_6b.branch7x7dbl_1.Conv2d_conv         [768, 128, 1, 1]    [3, 128, 17, 17]      98,304      85,229,568\n",
      "71_Mixed_6b.branch7x7dbl_1.BatchNorm2d_bn                 [128]    [3, 128, 17, 17]         256         443,904\n",
      "72_Mixed_6b.branch7x7dbl_2.Conv2d_conv         [128, 128, 7, 1]    [3, 128, 17, 17]     114,688      99,434,496\n",
      "73_Mixed_6b.branch7x7dbl_2.BatchNorm2d_bn                 [128]    [3, 128, 17, 17]         256         443,904\n",
      "74_Mixed_6b.branch7x7dbl_3.Conv2d_conv         [128, 128, 1, 7]    [3, 128, 17, 17]     114,688      99,434,496\n",
      "75_Mixed_6b.branch7x7dbl_3.BatchNorm2d_bn                 [128]    [3, 128, 17, 17]         256         443,904\n",
      "76_Mixed_6b.branch7x7dbl_4.Conv2d_conv         [128, 128, 7, 1]    [3, 128, 17, 17]     114,688      99,434,496\n",
      "77_Mixed_6b.branch7x7dbl_4.BatchNorm2d_bn                 [128]    [3, 128, 17, 17]         256         443,904\n",
      "78_Mixed_6b.branch7x7dbl_5.Conv2d_conv         [128, 192, 1, 7]    [3, 192, 17, 17]     172,032     149,151,744\n",
      "79_Mixed_6b.branch7x7dbl_5.BatchNorm2d_bn                 [192]    [3, 192, 17, 17]         384         665,856\n",
      "80_Mixed_6b.branch_pool.Conv2d_conv            [768, 192, 1, 1]    [3, 192, 17, 17]     147,456     127,844,352\n",
      "81_Mixed_6b.branch_pool.BatchNorm2d_bn                    [192]    [3, 192, 17, 17]         384         665,856\n",
      "82_Mixed_6c.branch1x1.Conv2d_conv              [768, 192, 1, 1]    [3, 192, 17, 17]     147,456     127,844,352\n",
      "83_Mixed_6c.branch1x1.BatchNorm2d_bn                      [192]    [3, 192, 17, 17]         384         665,856\n",
      "84_Mixed_6c.branch7x7_1.Conv2d_conv            [768, 160, 1, 1]    [3, 160, 17, 17]     122,880     106,536,960\n",
      "85_Mixed_6c.branch7x7_1.BatchNorm2d_bn                    [160]    [3, 160, 17, 17]         320         554,880\n",
      "86_Mixed_6c.branch7x7_2.Conv2d_conv            [160, 160, 1, 7]    [3, 160, 17, 17]     179,200     155,366,400\n",
      "87_Mixed_6c.branch7x7_2.BatchNorm2d_bn                    [160]    [3, 160, 17, 17]         320         554,880\n",
      "88_Mixed_6c.branch7x7_3.Conv2d_conv            [160, 192, 7, 1]    [3, 192, 17, 17]     215,040     186,439,680\n",
      "89_Mixed_6c.branch7x7_3.BatchNorm2d_bn                    [192]    [3, 192, 17, 17]         384         665,856\n",
      "90_Mixed_6c.branch7x7dbl_1.Conv2d_conv         [768, 160, 1, 1]    [3, 160, 17, 17]     122,880     106,536,960\n",
      "91_Mixed_6c.branch7x7dbl_1.BatchNorm2d_bn                 [160]    [3, 160, 17, 17]         320         554,880\n",
      "92_Mixed_6c.branch7x7dbl_2.Conv2d_conv         [160, 160, 7, 1]    [3, 160, 17, 17]     179,200     155,366,400\n",
      "93_Mixed_6c.branch7x7dbl_2.BatchNorm2d_bn                 [160]    [3, 160, 17, 17]         320         554,880\n",
      "94_Mixed_6c.branch7x7dbl_3.Conv2d_conv         [160, 160, 1, 7]    [3, 160, 17, 17]     179,200     155,366,400\n",
      "95_Mixed_6c.branch7x7dbl_3.BatchNorm2d_bn                 [160]    [3, 160, 17, 17]         320         554,880\n",
      "96_Mixed_6c.branch7x7dbl_4.Conv2d_conv         [160, 160, 7, 1]    [3, 160, 17, 17]     179,200     155,366,400\n",
      "97_Mixed_6c.branch7x7dbl_4.BatchNorm2d_bn                 [160]    [3, 160, 17, 17]         320         554,880\n",
      "98_Mixed_6c.branch7x7dbl_5.Conv2d_conv         [160, 192, 1, 7]    [3, 192, 17, 17]     215,040     186,439,680\n",
      "99_Mixed_6c.branch7x7dbl_5.BatchNorm2d_bn                 [192]    [3, 192, 17, 17]         384         665,856\n",
      "100_Mixed_6c.branch_pool.Conv2d_conv           [768, 192, 1, 1]    [3, 192, 17, 17]     147,456     127,844,352\n",
      "101_Mixed_6c.branch_pool.BatchNorm2d_bn                   [192]    [3, 192, 17, 17]         384         665,856\n",
      "102_Mixed_6d.branch1x1.Conv2d_conv             [768, 192, 1, 1]    [3, 192, 17, 17]     147,456     127,844,352\n",
      "103_Mixed_6d.branch1x1.BatchNorm2d_bn                     [192]    [3, 192, 17, 17]         384         665,856\n",
      "104_Mixed_6d.branch7x7_1.Conv2d_conv           [768, 160, 1, 1]    [3, 160, 17, 17]     122,880     106,536,960\n",
      "105_Mixed_6d.branch7x7_1.BatchNorm2d_bn                   [160]    [3, 160, 17, 17]         320         554,880\n",
      "106_Mixed_6d.branch7x7_2.Conv2d_conv           [160, 160, 1, 7]    [3, 160, 17, 17]     179,200     155,366,400\n",
      "107_Mixed_6d.branch7x7_2.BatchNorm2d_bn                   [160]    [3, 160, 17, 17]         320         554,880\n",
      "108_Mixed_6d.branch7x7_3.Conv2d_conv           [160, 192, 7, 1]    [3, 192, 17, 17]     215,040     186,439,680\n",
      "109_Mixed_6d.branch7x7_3.BatchNorm2d_bn                   [192]    [3, 192, 17, 17]         384         665,856\n",
      "110_Mixed_6d.branch7x7dbl_1.Conv2d_conv        [768, 160, 1, 1]    [3, 160, 17, 17]     122,880     106,536,960\n",
      "111_Mixed_6d.branch7x7dbl_1.BatchNorm2d_bn                [160]    [3, 160, 17, 17]         320         554,880\n",
      "112_Mixed_6d.branch7x7dbl_2.Conv2d_conv        [160, 160, 7, 1]    [3, 160, 17, 17]     179,200     155,366,400\n",
      "113_Mixed_6d.branch7x7dbl_2.BatchNorm2d_bn                [160]    [3, 160, 17, 17]         320         554,880\n",
      "114_Mixed_6d.branch7x7dbl_3.Conv2d_conv        [160, 160, 1, 7]    [3, 160, 17, 17]     179,200     155,366,400\n",
      "115_Mixed_6d.branch7x7dbl_3.BatchNorm2d_bn                [160]    [3, 160, 17, 17]         320         554,880\n",
      "116_Mixed_6d.branch7x7dbl_4.Conv2d_conv        [160, 160, 7, 1]    [3, 160, 17, 17]     179,200     155,366,400\n",
      "117_Mixed_6d.branch7x7dbl_4.BatchNorm2d_bn                [160]    [3, 160, 17, 17]         320         554,880\n",
      "118_Mixed_6d.branch7x7dbl_5.Conv2d_conv        [160, 192, 1, 7]    [3, 192, 17, 17]     215,040     186,439,680\n",
      "119_Mixed_6d.branch7x7dbl_5.BatchNorm2d_bn                [192]    [3, 192, 17, 17]         384         665,856\n",
      "120_Mixed_6d.branch_pool.Conv2d_conv           [768, 192, 1, 1]    [3, 192, 17, 17]     147,456     127,844,352\n",
      "121_Mixed_6d.branch_pool.BatchNorm2d_bn                   [192]    [3, 192, 17, 17]         384         665,856\n",
      "122_Mixed_6e.branch1x1.Conv2d_conv             [768, 192, 1, 1]    [3, 192, 17, 17]     147,456     127,844,352\n",
      "123_Mixed_6e.branch1x1.BatchNorm2d_bn                     [192]    [3, 192, 17, 17]         384         665,856\n",
      "124_Mixed_6e.branch7x7_1.Conv2d_conv           [768, 192, 1, 1]    [3, 192, 17, 17]     147,456     127,844,352\n",
      "125_Mixed_6e.branch7x7_1.BatchNorm2d_bn                   [192]    [3, 192, 17, 17]         384         665,856\n",
      "126_Mixed_6e.branch7x7_2.Conv2d_conv           [192, 192, 1, 7]    [3, 192, 17, 17]     258,048     223,727,616\n",
      "127_Mixed_6e.branch7x7_2.BatchNorm2d_bn                   [192]    [3, 192, 17, 17]         384         665,856\n",
      "128_Mixed_6e.branch7x7_3.Conv2d_conv           [192, 192, 7, 1]    [3, 192, 17, 17]     258,048     223,727,616\n",
      "129_Mixed_6e.branch7x7_3.BatchNorm2d_bn                   [192]    [3, 192, 17, 17]         384         665,856\n",
      "130_Mixed_6e.branch7x7dbl_1.Conv2d_conv        [768, 192, 1, 1]    [3, 192, 17, 17]     147,456     127,844,352\n",
      "131_Mixed_6e.branch7x7dbl_1.BatchNorm2d_bn                [192]    [3, 192, 17, 17]         384         665,856\n",
      "132_Mixed_6e.branch7x7dbl_2.Conv2d_conv        [192, 192, 7, 1]    [3, 192, 17, 17]     258,048     223,727,616\n",
      "133_Mixed_6e.branch7x7dbl_2.BatchNorm2d_bn                [192]    [3, 192, 17, 17]         384         665,856\n",
      "134_Mixed_6e.branch7x7dbl_3.Conv2d_conv        [192, 192, 1, 7]    [3, 192, 17, 17]     258,048     223,727,616\n",
      "135_Mixed_6e.branch7x7dbl_3.BatchNorm2d_bn                [192]    [3, 192, 17, 17]         384         665,856\n",
      "136_Mixed_6e.branch7x7dbl_4.Conv2d_conv        [192, 192, 7, 1]    [3, 192, 17, 17]     258,048     223,727,616\n",
      "137_Mixed_6e.branch7x7dbl_4.BatchNorm2d_bn                [192]    [3, 192, 17, 17]         384         665,856\n",
      "138_Mixed_6e.branch7x7dbl_5.Conv2d_conv        [192, 192, 1, 7]    [3, 192, 17, 17]     258,048     223,727,616\n",
      "139_Mixed_6e.branch7x7dbl_5.BatchNorm2d_bn                [192]    [3, 192, 17, 17]         384         665,856\n",
      "140_Mixed_6e.branch_pool.Conv2d_conv           [768, 192, 1, 1]    [3, 192, 17, 17]     147,456     127,844,352\n",
      "141_Mixed_6e.branch_pool.BatchNorm2d_bn                   [192]    [3, 192, 17, 17]         384         665,856\n",
      "142_AuxLogits.conv0.Conv2d_conv                [768, 128, 1, 1]      [3, 128, 5, 5]      98,304       7,372,800\n",
      "143_AuxLogits.conv0.BatchNorm2d_bn                        [128]      [3, 128, 5, 5]         256          38,400\n",
      "144_AuxLogits.conv1.Conv2d_conv                [128, 768, 5, 5]      [3, 768, 1, 1]   2,457,600       7,372,800\n",
      "145_AuxLogits.conv1.BatchNorm2d_bn                        [768]      [3, 768, 1, 1]       1,536           9,216\n",
      "146_AuxLogits.Linear_fc                             [768, 1000]           [3, 1000]     769,000       4,605,000\n",
      "147_Mixed_7a.branch3x3_1.Conv2d_conv           [768, 192, 1, 1]    [3, 192, 17, 17]     147,456     127,844,352\n",
      "148_Mixed_7a.branch3x3_1.BatchNorm2d_bn                   [192]    [3, 192, 17, 17]         384         665,856\n",
      "149_Mixed_7a.branch3x3_2.Conv2d_conv           [192, 320, 3, 3]      [3, 320, 8, 8]     552,960     106,168,320\n",
      "150_Mixed_7a.branch3x3_2.BatchNorm2d_bn                   [320]      [3, 320, 8, 8]         640         245,760\n",
      "151_Mixed_7a.branch7x7x3_1.Conv2d_conv         [768, 192, 1, 1]    [3, 192, 17, 17]     147,456     127,844,352\n",
      "152_Mixed_7a.branch7x7x3_1.BatchNorm2d_bn                 [192]    [3, 192, 17, 17]         384         665,856\n",
      "153_Mixed_7a.branch7x7x3_2.Conv2d_conv         [192, 192, 1, 7]    [3, 192, 17, 17]     258,048     223,727,616\n",
      "154_Mixed_7a.branch7x7x3_2.BatchNorm2d_bn                 [192]    [3, 192, 17, 17]         384         665,856\n",
      "155_Mixed_7a.branch7x7x3_3.Conv2d_conv         [192, 192, 7, 1]    [3, 192, 17, 17]     258,048     223,727,616\n",
      "156_Mixed_7a.branch7x7x3_3.BatchNorm2d_bn                 [192]    [3, 192, 17, 17]         384         665,856\n",
      "157_Mixed_7a.branch7x7x3_4.Conv2d_conv         [192, 192, 3, 3]      [3, 192, 8, 8]     331,776      63,700,992\n",
      "158_Mixed_7a.branch7x7x3_4.BatchNorm2d_bn                 [192]      [3, 192, 8, 8]         384         147,456\n",
      "159_Mixed_7b.branch1x1.Conv2d_conv            [1280, 320, 1, 1]      [3, 320, 8, 8]     409,600      78,643,200\n",
      "160_Mixed_7b.branch1x1.BatchNorm2d_bn                     [320]      [3, 320, 8, 8]         640         245,760\n",
      "161_Mixed_7b.branch3x3_1.Conv2d_conv          [1280, 384, 1, 1]      [3, 384, 8, 8]     491,520      94,371,840\n",
      "162_Mixed_7b.branch3x3_1.BatchNorm2d_bn                   [384]      [3, 384, 8, 8]         768         294,912\n",
      "163_Mixed_7b.branch3x3_2a.Conv2d_conv          [384, 384, 1, 3]      [3, 384, 8, 8]     442,368      84,934,656\n",
      "164_Mixed_7b.branch3x3_2a.BatchNorm2d_bn                  [384]      [3, 384, 8, 8]         768         294,912\n",
      "165_Mixed_7b.branch3x3_2b.Conv2d_conv          [384, 384, 3, 1]      [3, 384, 8, 8]     442,368      84,934,656\n",
      "166_Mixed_7b.branch3x3_2b.BatchNorm2d_bn                  [384]      [3, 384, 8, 8]         768         294,912\n",
      "167_Mixed_7b.branch3x3dbl_1.Conv2d_conv       [1280, 448, 1, 1]      [3, 448, 8, 8]     573,440     110,100,480\n",
      "168_Mixed_7b.branch3x3dbl_1.BatchNorm2d_bn                [448]      [3, 448, 8, 8]         896         344,064\n",
      "169_Mixed_7b.branch3x3dbl_2.Conv2d_conv        [448, 384, 3, 3]      [3, 384, 8, 8]   1,548,288     297,271,296\n",
      "170_Mixed_7b.branch3x3dbl_2.BatchNorm2d_bn                [384]      [3, 384, 8, 8]         768         294,912\n",
      "171_Mixed_7b.branch3x3dbl_3a.Conv2d_conv       [384, 384, 1, 3]      [3, 384, 8, 8]     442,368      84,934,656\n",
      "172_Mixed_7b.branch3x3dbl_3a.BatchNorm2d_bn               [384]      [3, 384, 8, 8]         768         294,912\n",
      "173_Mixed_7b.branch3x3dbl_3b.Conv2d_conv       [384, 384, 3, 1]      [3, 384, 8, 8]     442,368      84,934,656\n",
      "174_Mixed_7b.branch3x3dbl_3b.BatchNorm2d_bn               [384]      [3, 384, 8, 8]         768         294,912\n",
      "175_Mixed_7b.branch_pool.Conv2d_conv          [1280, 192, 1, 1]      [3, 192, 8, 8]     245,760      47,185,920\n",
      "176_Mixed_7b.branch_pool.BatchNorm2d_bn                   [192]      [3, 192, 8, 8]         384         147,456\n",
      "177_Mixed_7c.branch1x1.Conv2d_conv            [2048, 320, 1, 1]      [3, 320, 8, 8]     655,360     125,829,120\n",
      "178_Mixed_7c.branch1x1.BatchNorm2d_bn                     [320]      [3, 320, 8, 8]         640         245,760\n",
      "179_Mixed_7c.branch3x3_1.Conv2d_conv          [2048, 384, 1, 1]      [3, 384, 8, 8]     786,432     150,994,944\n",
      "180_Mixed_7c.branch3x3_1.BatchNorm2d_bn                   [384]      [3, 384, 8, 8]         768         294,912\n",
      "181_Mixed_7c.branch3x3_2a.Conv2d_conv          [384, 384, 1, 3]      [3, 384, 8, 8]     442,368      84,934,656\n",
      "182_Mixed_7c.branch3x3_2a.BatchNorm2d_bn                  [384]      [3, 384, 8, 8]         768         294,912\n",
      "183_Mixed_7c.branch3x3_2b.Conv2d_conv          [384, 384, 3, 1]      [3, 384, 8, 8]     442,368      84,934,656\n",
      "184_Mixed_7c.branch3x3_2b.BatchNorm2d_bn                  [384]      [3, 384, 8, 8]         768         294,912\n",
      "185_Mixed_7c.branch3x3dbl_1.Conv2d_conv       [2048, 448, 1, 1]      [3, 448, 8, 8]     917,504     176,160,768\n",
      "186_Mixed_7c.branch3x3dbl_1.BatchNorm2d_bn                [448]      [3, 448, 8, 8]         896         344,064\n",
      "187_Mixed_7c.branch3x3dbl_2.Conv2d_conv        [448, 384, 3, 3]      [3, 384, 8, 8]   1,548,288     297,271,296\n",
      "188_Mixed_7c.branch3x3dbl_2.BatchNorm2d_bn                [384]      [3, 384, 8, 8]         768         294,912\n",
      "189_Mixed_7c.branch3x3dbl_3a.Conv2d_conv       [384, 384, 1, 3]      [3, 384, 8, 8]     442,368      84,934,656\n",
      "190_Mixed_7c.branch3x3dbl_3a.BatchNorm2d_bn               [384]      [3, 384, 8, 8]         768         294,912\n",
      "191_Mixed_7c.branch3x3dbl_3b.Conv2d_conv       [384, 384, 3, 1]      [3, 384, 8, 8]     442,368      84,934,656\n",
      "192_Mixed_7c.branch3x3dbl_3b.BatchNorm2d_bn               [384]      [3, 384, 8, 8]         768         294,912\n",
      "193_Mixed_7c.branch_pool.Conv2d_conv          [2048, 192, 1, 1]      [3, 192, 8, 8]     393,216      75,497,472\n",
      "194_Mixed_7c.branch_pool.BatchNorm2d_bn                   [192]      [3, 192, 8, 8]         384         147,456\n",
      "195_avgpool                                                   -     [3, 2048, 1, 1]           0         399,360\n",
      "196_dropout                                                   -     [3, 2048, 1, 1]           0               0\n",
      "197_fc                                             [2048, 1000]           [3, 1000]   2,049,000      12,285,000\n",
      "===============================================================================================================\n",
      "Total params: 27,161,264\n",
      "Trainable params: 27,161,264\n",
      "Non-trainable params: 0\n",
      "Total FLOPs: 17,273,196,720 / 17.27 GFLOPs\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "Input size (MB): 3.07\n",
      "Forward/backward pass size (MB): 424.01\n",
      "Params size (MB): 103.61\n",
      "Estimated Total Size (MB): 530.69\n",
      "===============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "model.to(DEVICE)\n",
    "tu.get_model_summary(model, torch.randn(3, 3, 299, 299, device=DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.Resize((299, 299)),\n",
    "    T.ToTensor(), \n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "valid_dataset = datasets.ImageFolder(root=test_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 14034\n",
       "    Root location: /home/artemiy/nn_project/data/seg_train/seg_train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(299, 299), interpolation=bilinear, max_size=None, antialias=True)\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "           )"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'buildings': 0,\n",
       " 'forest': 1,\n",
       " 'glacier': 2,\n",
       " 'mountain': 3,\n",
       " 'sea': 4,\n",
       " 'street': 5}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2class = {j: i for i, j in train_dataset.class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'buildings',\n",
       " 1: 'forest',\n",
       " 2: 'glacier',\n",
       " 3: 'mountain',\n",
       " 4: 'sea',\n",
       " 5: 'street'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inception3(\n",
       "  (Conv2d_1a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2b_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv2d_3b_1x1): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_4a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Mixed_5b): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5d): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6a): InceptionB(\n",
       "    (branch3x3): BasicConv2d(\n",
       "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6b): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6c): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6d): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6e): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (AuxLogits): InceptionAux(\n",
       "    (conv0): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): BasicConv2d(\n",
       "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       "  (Mixed_7a): InceptionD(\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7b): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7c): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx2class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = torch.nn.Linear(2048, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================================\n",
      "Layer                                              Kernel              Output          Params             FLOPs\n",
      "===============================================================================================================\n",
      "0_Conv2d_1a_3x3.Conv2d_conv                       [3, 32, 3, 3]   [3, 32, 149, 149]         864      57,544,992\n",
      "1_Conv2d_1a_3x3.BatchNorm2d_bn                             [32]   [3, 32, 149, 149]          64       8,525,184\n",
      "2_Conv2d_2a_3x3.Conv2d_conv                      [32, 32, 3, 3]   [3, 32, 147, 147]       9,216     597,445,632\n",
      "3_Conv2d_2a_3x3.BatchNorm2d_bn                             [32]   [3, 32, 147, 147]          64       8,297,856\n",
      "4_Conv2d_2b_3x3.Conv2d_conv                      [32, 64, 3, 3]   [3, 64, 147, 147]      18,432   1,194,891,264\n",
      "5_Conv2d_2b_3x3.BatchNorm2d_bn                             [64]   [3, 64, 147, 147]         128      16,595,712\n",
      "6_maxpool1                                                    -     [3, 64, 73, 73]           0               0\n",
      "7_Conv2d_3b_1x1.Conv2d_conv                      [64, 80, 1, 1]     [3, 80, 73, 73]       5,120      81,853,440\n",
      "8_Conv2d_3b_1x1.BatchNorm2d_bn                             [80]     [3, 80, 73, 73]         160       5,115,840\n",
      "9_Conv2d_4a_3x3.Conv2d_conv                     [80, 192, 3, 3]    [3, 192, 71, 71]     138,240   2,090,603,520\n",
      "10_Conv2d_4a_3x3.BatchNorm2d_bn                           [192]    [3, 192, 71, 71]         384      11,614,464\n",
      "11_maxpool2                                                   -    [3, 192, 35, 35]           0               0\n",
      "12_Mixed_5b.branch1x1.Conv2d_conv               [192, 64, 1, 1]     [3, 64, 35, 35]      12,288      45,158,400\n",
      "13_Mixed_5b.branch1x1.BatchNorm2d_bn                       [64]     [3, 64, 35, 35]         128         940,800\n",
      "14_Mixed_5b.branch5x5_1.Conv2d_conv             [192, 48, 1, 1]     [3, 48, 35, 35]       9,216      33,868,800\n",
      "15_Mixed_5b.branch5x5_1.BatchNorm2d_bn                     [48]     [3, 48, 35, 35]          96         705,600\n",
      "16_Mixed_5b.branch5x5_2.Conv2d_conv              [48, 64, 5, 5]     [3, 64, 35, 35]      76,800     282,240,000\n",
      "17_Mixed_5b.branch5x5_2.BatchNorm2d_bn                     [64]     [3, 64, 35, 35]         128         940,800\n",
      "18_Mixed_5b.branch3x3dbl_1.Conv2d_conv          [192, 64, 1, 1]     [3, 64, 35, 35]      12,288      45,158,400\n",
      "19_Mixed_5b.branch3x3dbl_1.BatchNorm2d_bn                  [64]     [3, 64, 35, 35]         128         940,800\n",
      "20_Mixed_5b.branch3x3dbl_2.Conv2d_conv           [64, 96, 3, 3]     [3, 96, 35, 35]      55,296     203,212,800\n",
      "21_Mixed_5b.branch3x3dbl_2.BatchNorm2d_bn                  [96]     [3, 96, 35, 35]         192       1,411,200\n",
      "22_Mixed_5b.branch3x3dbl_3.Conv2d_conv           [96, 96, 3, 3]     [3, 96, 35, 35]      82,944     304,819,200\n",
      "23_Mixed_5b.branch3x3dbl_3.BatchNorm2d_bn                  [96]     [3, 96, 35, 35]         192       1,411,200\n",
      "24_Mixed_5b.branch_pool.Conv2d_conv             [192, 32, 1, 1]     [3, 32, 35, 35]       6,144      22,579,200\n",
      "25_Mixed_5b.branch_pool.BatchNorm2d_bn                     [32]     [3, 32, 35, 35]          64         470,400\n",
      "26_Mixed_5c.branch1x1.Conv2d_conv               [256, 64, 1, 1]     [3, 64, 35, 35]      16,384      60,211,200\n",
      "27_Mixed_5c.branch1x1.BatchNorm2d_bn                       [64]     [3, 64, 35, 35]         128         940,800\n",
      "28_Mixed_5c.branch5x5_1.Conv2d_conv             [256, 48, 1, 1]     [3, 48, 35, 35]      12,288      45,158,400\n",
      "29_Mixed_5c.branch5x5_1.BatchNorm2d_bn                     [48]     [3, 48, 35, 35]          96         705,600\n",
      "30_Mixed_5c.branch5x5_2.Conv2d_conv              [48, 64, 5, 5]     [3, 64, 35, 35]      76,800     282,240,000\n",
      "31_Mixed_5c.branch5x5_2.BatchNorm2d_bn                     [64]     [3, 64, 35, 35]         128         940,800\n",
      "32_Mixed_5c.branch3x3dbl_1.Conv2d_conv          [256, 64, 1, 1]     [3, 64, 35, 35]      16,384      60,211,200\n",
      "33_Mixed_5c.branch3x3dbl_1.BatchNorm2d_bn                  [64]     [3, 64, 35, 35]         128         940,800\n",
      "34_Mixed_5c.branch3x3dbl_2.Conv2d_conv           [64, 96, 3, 3]     [3, 96, 35, 35]      55,296     203,212,800\n",
      "35_Mixed_5c.branch3x3dbl_2.BatchNorm2d_bn                  [96]     [3, 96, 35, 35]         192       1,411,200\n",
      "36_Mixed_5c.branch3x3dbl_3.Conv2d_conv           [96, 96, 3, 3]     [3, 96, 35, 35]      82,944     304,819,200\n",
      "37_Mixed_5c.branch3x3dbl_3.BatchNorm2d_bn                  [96]     [3, 96, 35, 35]         192       1,411,200\n",
      "38_Mixed_5c.branch_pool.Conv2d_conv             [256, 64, 1, 1]     [3, 64, 35, 35]      16,384      60,211,200\n",
      "39_Mixed_5c.branch_pool.BatchNorm2d_bn                     [64]     [3, 64, 35, 35]         128         940,800\n",
      "40_Mixed_5d.branch1x1.Conv2d_conv               [288, 64, 1, 1]     [3, 64, 35, 35]      18,432      67,737,600\n",
      "41_Mixed_5d.branch1x1.BatchNorm2d_bn                       [64]     [3, 64, 35, 35]         128         940,800\n",
      "42_Mixed_5d.branch5x5_1.Conv2d_conv             [288, 48, 1, 1]     [3, 48, 35, 35]      13,824      50,803,200\n",
      "43_Mixed_5d.branch5x5_1.BatchNorm2d_bn                     [48]     [3, 48, 35, 35]          96         705,600\n",
      "44_Mixed_5d.branch5x5_2.Conv2d_conv              [48, 64, 5, 5]     [3, 64, 35, 35]      76,800     282,240,000\n",
      "45_Mixed_5d.branch5x5_2.BatchNorm2d_bn                     [64]     [3, 64, 35, 35]         128         940,800\n",
      "46_Mixed_5d.branch3x3dbl_1.Conv2d_conv          [288, 64, 1, 1]     [3, 64, 35, 35]      18,432      67,737,600\n",
      "47_Mixed_5d.branch3x3dbl_1.BatchNorm2d_bn                  [64]     [3, 64, 35, 35]         128         940,800\n",
      "48_Mixed_5d.branch3x3dbl_2.Conv2d_conv           [64, 96, 3, 3]     [3, 96, 35, 35]      55,296     203,212,800\n",
      "49_Mixed_5d.branch3x3dbl_2.BatchNorm2d_bn                  [96]     [3, 96, 35, 35]         192       1,411,200\n",
      "50_Mixed_5d.branch3x3dbl_3.Conv2d_conv           [96, 96, 3, 3]     [3, 96, 35, 35]      82,944     304,819,200\n",
      "51_Mixed_5d.branch3x3dbl_3.BatchNorm2d_bn                  [96]     [3, 96, 35, 35]         192       1,411,200\n",
      "52_Mixed_5d.branch_pool.Conv2d_conv             [288, 64, 1, 1]     [3, 64, 35, 35]      18,432      67,737,600\n",
      "53_Mixed_5d.branch_pool.BatchNorm2d_bn                     [64]     [3, 64, 35, 35]         128         940,800\n",
      "54_Mixed_6a.branch3x3.Conv2d_conv              [288, 384, 3, 3]    [3, 384, 17, 17]     995,328     862,949,376\n",
      "55_Mixed_6a.branch3x3.BatchNorm2d_bn                      [384]    [3, 384, 17, 17]         768       1,331,712\n",
      "56_Mixed_6a.branch3x3dbl_1.Conv2d_conv          [288, 64, 1, 1]     [3, 64, 35, 35]      18,432      67,737,600\n",
      "57_Mixed_6a.branch3x3dbl_1.BatchNorm2d_bn                  [64]     [3, 64, 35, 35]         128         940,800\n",
      "58_Mixed_6a.branch3x3dbl_2.Conv2d_conv           [64, 96, 3, 3]     [3, 96, 35, 35]      55,296     203,212,800\n",
      "59_Mixed_6a.branch3x3dbl_2.BatchNorm2d_bn                  [96]     [3, 96, 35, 35]         192       1,411,200\n",
      "60_Mixed_6a.branch3x3dbl_3.Conv2d_conv           [96, 96, 3, 3]     [3, 96, 17, 17]      82,944      71,912,448\n",
      "61_Mixed_6a.branch3x3dbl_3.BatchNorm2d_bn                  [96]     [3, 96, 17, 17]         192         332,928\n",
      "62_Mixed_6b.branch1x1.Conv2d_conv              [768, 192, 1, 1]    [3, 192, 17, 17]     147,456     127,844,352\n",
      "63_Mixed_6b.branch1x1.BatchNorm2d_bn                      [192]    [3, 192, 17, 17]         384         665,856\n",
      "64_Mixed_6b.branch7x7_1.Conv2d_conv            [768, 128, 1, 1]    [3, 128, 17, 17]      98,304      85,229,568\n",
      "65_Mixed_6b.branch7x7_1.BatchNorm2d_bn                    [128]    [3, 128, 17, 17]         256         443,904\n",
      "66_Mixed_6b.branch7x7_2.Conv2d_conv            [128, 128, 1, 7]    [3, 128, 17, 17]     114,688      99,434,496\n",
      "67_Mixed_6b.branch7x7_2.BatchNorm2d_bn                    [128]    [3, 128, 17, 17]         256         443,904\n",
      "68_Mixed_6b.branch7x7_3.Conv2d_conv            [128, 192, 7, 1]    [3, 192, 17, 17]     172,032     149,151,744\n",
      "69_Mixed_6b.branch7x7_3.BatchNorm2d_bn                    [192]    [3, 192, 17, 17]         384         665,856\n",
      "70_Mixed_6b.branch7x7dbl_1.Conv2d_conv         [768, 128, 1, 1]    [3, 128, 17, 17]      98,304      85,229,568\n",
      "71_Mixed_6b.branch7x7dbl_1.BatchNorm2d_bn                 [128]    [3, 128, 17, 17]         256         443,904\n",
      "72_Mixed_6b.branch7x7dbl_2.Conv2d_conv         [128, 128, 7, 1]    [3, 128, 17, 17]     114,688      99,434,496\n",
      "73_Mixed_6b.branch7x7dbl_2.BatchNorm2d_bn                 [128]    [3, 128, 17, 17]         256         443,904\n",
      "74_Mixed_6b.branch7x7dbl_3.Conv2d_conv         [128, 128, 1, 7]    [3, 128, 17, 17]     114,688      99,434,496\n",
      "75_Mixed_6b.branch7x7dbl_3.BatchNorm2d_bn                 [128]    [3, 128, 17, 17]         256         443,904\n",
      "76_Mixed_6b.branch7x7dbl_4.Conv2d_conv         [128, 128, 7, 1]    [3, 128, 17, 17]     114,688      99,434,496\n",
      "77_Mixed_6b.branch7x7dbl_4.BatchNorm2d_bn                 [128]    [3, 128, 17, 17]         256         443,904\n",
      "78_Mixed_6b.branch7x7dbl_5.Conv2d_conv         [128, 192, 1, 7]    [3, 192, 17, 17]     172,032     149,151,744\n",
      "79_Mixed_6b.branch7x7dbl_5.BatchNorm2d_bn                 [192]    [3, 192, 17, 17]         384         665,856\n",
      "80_Mixed_6b.branch_pool.Conv2d_conv            [768, 192, 1, 1]    [3, 192, 17, 17]     147,456     127,844,352\n",
      "81_Mixed_6b.branch_pool.BatchNorm2d_bn                    [192]    [3, 192, 17, 17]         384         665,856\n",
      "82_Mixed_6c.branch1x1.Conv2d_conv              [768, 192, 1, 1]    [3, 192, 17, 17]     147,456     127,844,352\n",
      "83_Mixed_6c.branch1x1.BatchNorm2d_bn                      [192]    [3, 192, 17, 17]         384         665,856\n",
      "84_Mixed_6c.branch7x7_1.Conv2d_conv            [768, 160, 1, 1]    [3, 160, 17, 17]     122,880     106,536,960\n",
      "85_Mixed_6c.branch7x7_1.BatchNorm2d_bn                    [160]    [3, 160, 17, 17]         320         554,880\n",
      "86_Mixed_6c.branch7x7_2.Conv2d_conv            [160, 160, 1, 7]    [3, 160, 17, 17]     179,200     155,366,400\n",
      "87_Mixed_6c.branch7x7_2.BatchNorm2d_bn                    [160]    [3, 160, 17, 17]         320         554,880\n",
      "88_Mixed_6c.branch7x7_3.Conv2d_conv            [160, 192, 7, 1]    [3, 192, 17, 17]     215,040     186,439,680\n",
      "89_Mixed_6c.branch7x7_3.BatchNorm2d_bn                    [192]    [3, 192, 17, 17]         384         665,856\n",
      "90_Mixed_6c.branch7x7dbl_1.Conv2d_conv         [768, 160, 1, 1]    [3, 160, 17, 17]     122,880     106,536,960\n",
      "91_Mixed_6c.branch7x7dbl_1.BatchNorm2d_bn                 [160]    [3, 160, 17, 17]         320         554,880\n",
      "92_Mixed_6c.branch7x7dbl_2.Conv2d_conv         [160, 160, 7, 1]    [3, 160, 17, 17]     179,200     155,366,400\n",
      "93_Mixed_6c.branch7x7dbl_2.BatchNorm2d_bn                 [160]    [3, 160, 17, 17]         320         554,880\n",
      "94_Mixed_6c.branch7x7dbl_3.Conv2d_conv         [160, 160, 1, 7]    [3, 160, 17, 17]     179,200     155,366,400\n",
      "95_Mixed_6c.branch7x7dbl_3.BatchNorm2d_bn                 [160]    [3, 160, 17, 17]         320         554,880\n",
      "96_Mixed_6c.branch7x7dbl_4.Conv2d_conv         [160, 160, 7, 1]    [3, 160, 17, 17]     179,200     155,366,400\n",
      "97_Mixed_6c.branch7x7dbl_4.BatchNorm2d_bn                 [160]    [3, 160, 17, 17]         320         554,880\n",
      "98_Mixed_6c.branch7x7dbl_5.Conv2d_conv         [160, 192, 1, 7]    [3, 192, 17, 17]     215,040     186,439,680\n",
      "99_Mixed_6c.branch7x7dbl_5.BatchNorm2d_bn                 [192]    [3, 192, 17, 17]         384         665,856\n",
      "100_Mixed_6c.branch_pool.Conv2d_conv           [768, 192, 1, 1]    [3, 192, 17, 17]     147,456     127,844,352\n",
      "101_Mixed_6c.branch_pool.BatchNorm2d_bn                   [192]    [3, 192, 17, 17]         384         665,856\n",
      "102_Mixed_6d.branch1x1.Conv2d_conv             [768, 192, 1, 1]    [3, 192, 17, 17]     147,456     127,844,352\n",
      "103_Mixed_6d.branch1x1.BatchNorm2d_bn                     [192]    [3, 192, 17, 17]         384         665,856\n",
      "104_Mixed_6d.branch7x7_1.Conv2d_conv           [768, 160, 1, 1]    [3, 160, 17, 17]     122,880     106,536,960\n",
      "105_Mixed_6d.branch7x7_1.BatchNorm2d_bn                   [160]    [3, 160, 17, 17]         320         554,880\n",
      "106_Mixed_6d.branch7x7_2.Conv2d_conv           [160, 160, 1, 7]    [3, 160, 17, 17]     179,200     155,366,400\n",
      "107_Mixed_6d.branch7x7_2.BatchNorm2d_bn                   [160]    [3, 160, 17, 17]         320         554,880\n",
      "108_Mixed_6d.branch7x7_3.Conv2d_conv           [160, 192, 7, 1]    [3, 192, 17, 17]     215,040     186,439,680\n",
      "109_Mixed_6d.branch7x7_3.BatchNorm2d_bn                   [192]    [3, 192, 17, 17]         384         665,856\n",
      "110_Mixed_6d.branch7x7dbl_1.Conv2d_conv        [768, 160, 1, 1]    [3, 160, 17, 17]     122,880     106,536,960\n",
      "111_Mixed_6d.branch7x7dbl_1.BatchNorm2d_bn                [160]    [3, 160, 17, 17]         320         554,880\n",
      "112_Mixed_6d.branch7x7dbl_2.Conv2d_conv        [160, 160, 7, 1]    [3, 160, 17, 17]     179,200     155,366,400\n",
      "113_Mixed_6d.branch7x7dbl_2.BatchNorm2d_bn                [160]    [3, 160, 17, 17]         320         554,880\n",
      "114_Mixed_6d.branch7x7dbl_3.Conv2d_conv        [160, 160, 1, 7]    [3, 160, 17, 17]     179,200     155,366,400\n",
      "115_Mixed_6d.branch7x7dbl_3.BatchNorm2d_bn                [160]    [3, 160, 17, 17]         320         554,880\n",
      "116_Mixed_6d.branch7x7dbl_4.Conv2d_conv        [160, 160, 7, 1]    [3, 160, 17, 17]     179,200     155,366,400\n",
      "117_Mixed_6d.branch7x7dbl_4.BatchNorm2d_bn                [160]    [3, 160, 17, 17]         320         554,880\n",
      "118_Mixed_6d.branch7x7dbl_5.Conv2d_conv        [160, 192, 1, 7]    [3, 192, 17, 17]     215,040     186,439,680\n",
      "119_Mixed_6d.branch7x7dbl_5.BatchNorm2d_bn                [192]    [3, 192, 17, 17]         384         665,856\n",
      "120_Mixed_6d.branch_pool.Conv2d_conv           [768, 192, 1, 1]    [3, 192, 17, 17]     147,456     127,844,352\n",
      "121_Mixed_6d.branch_pool.BatchNorm2d_bn                   [192]    [3, 192, 17, 17]         384         665,856\n",
      "122_Mixed_6e.branch1x1.Conv2d_conv             [768, 192, 1, 1]    [3, 192, 17, 17]     147,456     127,844,352\n",
      "123_Mixed_6e.branch1x1.BatchNorm2d_bn                     [192]    [3, 192, 17, 17]         384         665,856\n",
      "124_Mixed_6e.branch7x7_1.Conv2d_conv           [768, 192, 1, 1]    [3, 192, 17, 17]     147,456     127,844,352\n",
      "125_Mixed_6e.branch7x7_1.BatchNorm2d_bn                   [192]    [3, 192, 17, 17]         384         665,856\n",
      "126_Mixed_6e.branch7x7_2.Conv2d_conv           [192, 192, 1, 7]    [3, 192, 17, 17]     258,048     223,727,616\n",
      "127_Mixed_6e.branch7x7_2.BatchNorm2d_bn                   [192]    [3, 192, 17, 17]         384         665,856\n",
      "128_Mixed_6e.branch7x7_3.Conv2d_conv           [192, 192, 7, 1]    [3, 192, 17, 17]     258,048     223,727,616\n",
      "129_Mixed_6e.branch7x7_3.BatchNorm2d_bn                   [192]    [3, 192, 17, 17]         384         665,856\n",
      "130_Mixed_6e.branch7x7dbl_1.Conv2d_conv        [768, 192, 1, 1]    [3, 192, 17, 17]     147,456     127,844,352\n",
      "131_Mixed_6e.branch7x7dbl_1.BatchNorm2d_bn                [192]    [3, 192, 17, 17]         384         665,856\n",
      "132_Mixed_6e.branch7x7dbl_2.Conv2d_conv        [192, 192, 7, 1]    [3, 192, 17, 17]     258,048     223,727,616\n",
      "133_Mixed_6e.branch7x7dbl_2.BatchNorm2d_bn                [192]    [3, 192, 17, 17]         384         665,856\n",
      "134_Mixed_6e.branch7x7dbl_3.Conv2d_conv        [192, 192, 1, 7]    [3, 192, 17, 17]     258,048     223,727,616\n",
      "135_Mixed_6e.branch7x7dbl_3.BatchNorm2d_bn                [192]    [3, 192, 17, 17]         384         665,856\n",
      "136_Mixed_6e.branch7x7dbl_4.Conv2d_conv        [192, 192, 7, 1]    [3, 192, 17, 17]     258,048     223,727,616\n",
      "137_Mixed_6e.branch7x7dbl_4.BatchNorm2d_bn                [192]    [3, 192, 17, 17]         384         665,856\n",
      "138_Mixed_6e.branch7x7dbl_5.Conv2d_conv        [192, 192, 1, 7]    [3, 192, 17, 17]     258,048     223,727,616\n",
      "139_Mixed_6e.branch7x7dbl_5.BatchNorm2d_bn                [192]    [3, 192, 17, 17]         384         665,856\n",
      "140_Mixed_6e.branch_pool.Conv2d_conv           [768, 192, 1, 1]    [3, 192, 17, 17]     147,456     127,844,352\n",
      "141_Mixed_6e.branch_pool.BatchNorm2d_bn                   [192]    [3, 192, 17, 17]         384         665,856\n",
      "142_AuxLogits.conv0.Conv2d_conv                [768, 128, 1, 1]      [3, 128, 5, 5]      98,304       7,372,800\n",
      "143_AuxLogits.conv0.BatchNorm2d_bn                        [128]      [3, 128, 5, 5]         256          38,400\n",
      "144_AuxLogits.conv1.Conv2d_conv                [128, 768, 5, 5]      [3, 768, 1, 1]   2,457,600       7,372,800\n",
      "145_AuxLogits.conv1.BatchNorm2d_bn                        [768]      [3, 768, 1, 1]       1,536           9,216\n",
      "146_AuxLogits.Linear_fc                             [768, 1000]           [3, 1000]     769,000       4,605,000\n",
      "147_Mixed_7a.branch3x3_1.Conv2d_conv           [768, 192, 1, 1]    [3, 192, 17, 17]     147,456     127,844,352\n",
      "148_Mixed_7a.branch3x3_1.BatchNorm2d_bn                   [192]    [3, 192, 17, 17]         384         665,856\n",
      "149_Mixed_7a.branch3x3_2.Conv2d_conv           [192, 320, 3, 3]      [3, 320, 8, 8]     552,960     106,168,320\n",
      "150_Mixed_7a.branch3x3_2.BatchNorm2d_bn                   [320]      [3, 320, 8, 8]         640         245,760\n",
      "151_Mixed_7a.branch7x7x3_1.Conv2d_conv         [768, 192, 1, 1]    [3, 192, 17, 17]     147,456     127,844,352\n",
      "152_Mixed_7a.branch7x7x3_1.BatchNorm2d_bn                 [192]    [3, 192, 17, 17]         384         665,856\n",
      "153_Mixed_7a.branch7x7x3_2.Conv2d_conv         [192, 192, 1, 7]    [3, 192, 17, 17]     258,048     223,727,616\n",
      "154_Mixed_7a.branch7x7x3_2.BatchNorm2d_bn                 [192]    [3, 192, 17, 17]         384         665,856\n",
      "155_Mixed_7a.branch7x7x3_3.Conv2d_conv         [192, 192, 7, 1]    [3, 192, 17, 17]     258,048     223,727,616\n",
      "156_Mixed_7a.branch7x7x3_3.BatchNorm2d_bn                 [192]    [3, 192, 17, 17]         384         665,856\n",
      "157_Mixed_7a.branch7x7x3_4.Conv2d_conv         [192, 192, 3, 3]      [3, 192, 8, 8]     331,776      63,700,992\n",
      "158_Mixed_7a.branch7x7x3_4.BatchNorm2d_bn                 [192]      [3, 192, 8, 8]         384         147,456\n",
      "159_Mixed_7b.branch1x1.Conv2d_conv            [1280, 320, 1, 1]      [3, 320, 8, 8]     409,600      78,643,200\n",
      "160_Mixed_7b.branch1x1.BatchNorm2d_bn                     [320]      [3, 320, 8, 8]         640         245,760\n",
      "161_Mixed_7b.branch3x3_1.Conv2d_conv          [1280, 384, 1, 1]      [3, 384, 8, 8]     491,520      94,371,840\n",
      "162_Mixed_7b.branch3x3_1.BatchNorm2d_bn                   [384]      [3, 384, 8, 8]         768         294,912\n",
      "163_Mixed_7b.branch3x3_2a.Conv2d_conv          [384, 384, 1, 3]      [3, 384, 8, 8]     442,368      84,934,656\n",
      "164_Mixed_7b.branch3x3_2a.BatchNorm2d_bn                  [384]      [3, 384, 8, 8]         768         294,912\n",
      "165_Mixed_7b.branch3x3_2b.Conv2d_conv          [384, 384, 3, 1]      [3, 384, 8, 8]     442,368      84,934,656\n",
      "166_Mixed_7b.branch3x3_2b.BatchNorm2d_bn                  [384]      [3, 384, 8, 8]         768         294,912\n",
      "167_Mixed_7b.branch3x3dbl_1.Conv2d_conv       [1280, 448, 1, 1]      [3, 448, 8, 8]     573,440     110,100,480\n",
      "168_Mixed_7b.branch3x3dbl_1.BatchNorm2d_bn                [448]      [3, 448, 8, 8]         896         344,064\n",
      "169_Mixed_7b.branch3x3dbl_2.Conv2d_conv        [448, 384, 3, 3]      [3, 384, 8, 8]   1,548,288     297,271,296\n",
      "170_Mixed_7b.branch3x3dbl_2.BatchNorm2d_bn                [384]      [3, 384, 8, 8]         768         294,912\n",
      "171_Mixed_7b.branch3x3dbl_3a.Conv2d_conv       [384, 384, 1, 3]      [3, 384, 8, 8]     442,368      84,934,656\n",
      "172_Mixed_7b.branch3x3dbl_3a.BatchNorm2d_bn               [384]      [3, 384, 8, 8]         768         294,912\n",
      "173_Mixed_7b.branch3x3dbl_3b.Conv2d_conv       [384, 384, 3, 1]      [3, 384, 8, 8]     442,368      84,934,656\n",
      "174_Mixed_7b.branch3x3dbl_3b.BatchNorm2d_bn               [384]      [3, 384, 8, 8]         768         294,912\n",
      "175_Mixed_7b.branch_pool.Conv2d_conv          [1280, 192, 1, 1]      [3, 192, 8, 8]     245,760      47,185,920\n",
      "176_Mixed_7b.branch_pool.BatchNorm2d_bn                   [192]      [3, 192, 8, 8]         384         147,456\n",
      "177_Mixed_7c.branch1x1.Conv2d_conv            [2048, 320, 1, 1]      [3, 320, 8, 8]     655,360     125,829,120\n",
      "178_Mixed_7c.branch1x1.BatchNorm2d_bn                     [320]      [3, 320, 8, 8]         640         245,760\n",
      "179_Mixed_7c.branch3x3_1.Conv2d_conv          [2048, 384, 1, 1]      [3, 384, 8, 8]     786,432     150,994,944\n",
      "180_Mixed_7c.branch3x3_1.BatchNorm2d_bn                   [384]      [3, 384, 8, 8]         768         294,912\n",
      "181_Mixed_7c.branch3x3_2a.Conv2d_conv          [384, 384, 1, 3]      [3, 384, 8, 8]     442,368      84,934,656\n",
      "182_Mixed_7c.branch3x3_2a.BatchNorm2d_bn                  [384]      [3, 384, 8, 8]         768         294,912\n",
      "183_Mixed_7c.branch3x3_2b.Conv2d_conv          [384, 384, 3, 1]      [3, 384, 8, 8]     442,368      84,934,656\n",
      "184_Mixed_7c.branch3x3_2b.BatchNorm2d_bn                  [384]      [3, 384, 8, 8]         768         294,912\n",
      "185_Mixed_7c.branch3x3dbl_1.Conv2d_conv       [2048, 448, 1, 1]      [3, 448, 8, 8]     917,504     176,160,768\n",
      "186_Mixed_7c.branch3x3dbl_1.BatchNorm2d_bn                [448]      [3, 448, 8, 8]         896         344,064\n",
      "187_Mixed_7c.branch3x3dbl_2.Conv2d_conv        [448, 384, 3, 3]      [3, 384, 8, 8]   1,548,288     297,271,296\n",
      "188_Mixed_7c.branch3x3dbl_2.BatchNorm2d_bn                [384]      [3, 384, 8, 8]         768         294,912\n",
      "189_Mixed_7c.branch3x3dbl_3a.Conv2d_conv       [384, 384, 1, 3]      [3, 384, 8, 8]     442,368      84,934,656\n",
      "190_Mixed_7c.branch3x3dbl_3a.BatchNorm2d_bn               [384]      [3, 384, 8, 8]         768         294,912\n",
      "191_Mixed_7c.branch3x3dbl_3b.Conv2d_conv       [384, 384, 3, 1]      [3, 384, 8, 8]     442,368      84,934,656\n",
      "192_Mixed_7c.branch3x3dbl_3b.BatchNorm2d_bn               [384]      [3, 384, 8, 8]         768         294,912\n",
      "193_Mixed_7c.branch_pool.Conv2d_conv          [2048, 192, 1, 1]      [3, 192, 8, 8]     393,216      75,497,472\n",
      "194_Mixed_7c.branch_pool.BatchNorm2d_bn                   [192]      [3, 192, 8, 8]         384         147,456\n",
      "195_avgpool                                                   -     [3, 2048, 1, 1]           0         399,360\n",
      "196_dropout                                                   -     [3, 2048, 1, 1]           0               0\n",
      "197_fc                                                [2048, 6]              [3, 6]      12,294          73,710\n",
      "===============================================================================================================\n",
      "Total params: 25,124,558\n",
      "Trainable params: 25,124,558\n",
      "Non-trainable params: 0\n",
      "Total FLOPs: 17,260,985,430 / 17.26 GFLOPs\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "Input size (MB): 3.07\n",
      "Forward/backward pass size (MB): 423.99\n",
      "Params size (MB): 95.84\n",
      "Estimated Total Size (MB): 522.90\n",
      "===============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "model.to(DEVICE)\n",
    "tu.get_model_summary(model, torch.randn(3, 3, 299, 299, device=DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.fc.parameters():\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.002\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(\n",
    "    model: nn.Module,\n",
    "    epochs: int,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    train_loader: DataLoader,\n",
    "    valid_loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    device: torch.device,\n",
    "    history=None,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    model: pytorch model - model to train\n",
    "    epochs: int          - number of epochs\n",
    "    optimizer: torch.optim.Optimizer - optimizer for training\n",
    "    train_loader: DataLoader - DataLoader for training data\n",
    "    valid_loader: DataLoader - DataLoader for validation data\n",
    "    criterion: nn.Module - loss function\n",
    "    device: torch.device - device to train on\n",
    "    history: dict - dictionary to store training history\n",
    "    \"\"\"\n",
    "\n",
    "    # будем сохранять значения точности и лосса в history\n",
    "    history = history or {\n",
    "        \"train_accs\": [],\n",
    "        \"train_losses\": [],\n",
    "        \"valid_accs\": [],\n",
    "        \"valid_losses\": [],\n",
    "    }\n",
    "\n",
    "    # определяем текущую эпоху обучения\n",
    "    start_epoch = len(history[\"train_accs\"])\n",
    "    for epoch in range(start_epoch + 1, start_epoch + epochs + 1):\n",
    "        print(f'{\"-\"*13} Epoch {epoch} {\"-\"*13}')\n",
    "\n",
    "        model.train()\n",
    "        batch_accs = []\n",
    "        batch_losses = []\n",
    "        for samples, labels in train_loader:\n",
    "\n",
    "            samples = samples.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            y_pred = model(samples)\n",
    "\n",
    "            # Используем основной выход (logits) из InceptionOutputs\n",
    "            if isinstance(y_pred, tuple):\n",
    "                y_pred = y_pred.logits\n",
    "\n",
    "            # Считаем лосс\n",
    "            loss = criterion(y_pred, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_losses.append(loss.item())\n",
    "\n",
    "            # сравниваем предсказания с таргетом и добавляем в\n",
    "            # список значение точности\n",
    "            batch_accs.append((y_pred.argmax(axis=1) == labels).cpu().numpy().mean())\n",
    "\n",
    "        history[\"train_losses\"].append(np.mean(batch_losses))\n",
    "        history[\"train_accs\"].append(np.mean(batch_accs))\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "\n",
    "        batch_accs = []\n",
    "        batch_losses = []\n",
    "        for samples, labels in valid_loader:\n",
    "            with torch.no_grad():\n",
    "                y_pred = model(samples.to(device))\n",
    "\n",
    "                # Используем основной выход (logits) из InceptionOutputs\n",
    "                if isinstance(y_pred, tuple):\n",
    "                    y_pred = y_pred.logits\n",
    "\n",
    "            loss = criterion(y_pred, labels.to(device))\n",
    "            batch_losses.append(loss.item())\n",
    "            batch_accs.append(\n",
    "                (y_pred.cpu().argmax(axis=1) == labels.cpu()).numpy().mean()\n",
    "            )\n",
    "        history[\"valid_accs\"].append(np.mean(batch_accs))\n",
    "        history[\"valid_losses\"].append(np.mean(batch_losses))\n",
    "\n",
    "        # печатаем результат\n",
    "\n",
    "        print(\n",
    "            f'train: accuracy {history[\"train_accs\"][-1]:.4f}, loss {history[\"train_losses\"][-1]:.4f}\\n'\n",
    "            f'valid: accuracy {history[\"valid_accs\"][-1]:.4f}, loss {history[\"valid_losses\"][-1]:.4f}'\n",
    "        )\n",
    "        print(f'{\"-\"*35}')\n",
    "        print()\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Epoch 1 -------------\n",
      "train: accuracy 0.1428, loss 1.8564\n",
      "valid: accuracy 0.1301, loss 1.8381\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 2 -------------\n",
      "train: accuracy 0.1495, loss 1.8499\n",
      "valid: accuracy 0.1341, loss 1.8350\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 3 -------------\n",
      "train: accuracy 0.1451, loss 1.8543\n",
      "valid: accuracy 0.1323, loss 1.8366\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 4 -------------\n",
      "train: accuracy 0.1440, loss 1.8526\n",
      "valid: accuracy 0.1357, loss 1.8375\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 5 -------------\n",
      "train: accuracy 0.1522, loss 1.8518\n",
      "valid: accuracy 0.1355, loss 1.8372\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 6 -------------\n",
      "train: accuracy 0.1468, loss 1.8542\n",
      "valid: accuracy 0.1389, loss 1.8366\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 7 -------------\n",
      "train: accuracy 0.1438, loss 1.8540\n",
      "valid: accuracy 0.1316, loss 1.8361\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 8 -------------\n",
      "train: accuracy 0.1523, loss 1.8513\n",
      "valid: accuracy 0.1304, loss 1.8369\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 9 -------------\n",
      "train: accuracy 0.1500, loss 1.8518\n",
      "valid: accuracy 0.1334, loss 1.8348\n",
      "-----------------------------------\n",
      "\n",
      "------------- Epoch 10 -------------\n",
      "train: accuracy 0.1513, loss 1.8533\n",
      "valid: accuracy 0.1307, loss 1.8369\n",
      "-----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history1 = fit_model(\n",
    "    model=model,\n",
    "    epochs=10,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    criterion=criterion,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artemiy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
